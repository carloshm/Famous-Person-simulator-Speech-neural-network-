{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 710M (CNMeM is enabled with initial size: 85.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 131264\n"
     ]
    }
   ],
   "source": [
    "#path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(\"duda.txt\").read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nazwa 'tail' nie jest rozpoznawana jako polecenie wewn©trzne lub zewn©trzne,\n",
      "program wykonywalny lub plik wsadowy.\n"
     ]
    }
   ],
   "source": [
    "!tail {path} -n25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 70\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"%()+,-.0123456789:?abcdefghijklmnopqrstuvwxyz\\x84\\x8c\\x92\\x94\\x96\\x9c\\x9f\\xa3\\xad\\xaf\\xb3\\xb9\\xbf\\xc1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 49, 24, 37, 38, 46, 37, 32, 2, 39]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'szanowni pa\\xf1stwo marsza\\xb3kowie i marsza\\xb3kowie seniorzy,\\nszanowna pani p'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 131257\n"
     ]
    }
   ],
   "source": [
    "maxlen = 8\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131255L, 8L), (131255L, 8L))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"szanowny\"\n",
    "    for i in range(500):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-8:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2029s - loss: 1.6267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1914d6a0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=32, nb_epoch=1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebrkowych go�cie - �adowszego nadlatemu ona niepodleg�e podosta� partnerskich tego, co 15  pzycy szanszej na najlepsze w stanie za polska nie by�o ju� o�wodnia czasem polsce polski. ale te� tar� polskiego wyz�r, �e przed na tym, kt�rzy dla naszych przysz�o�ci. nowoczesnym rzeczypospolitej, zapalczywy na wszystkim si� rozw�juc�w na innego najwa�niejse projektywnego ? prosi�. kt�ra prze�odowania � i przyj��em dzia�alno�� na pa�stwo m�wi�, to jak �udziom wielkie poblicznego. bardzo serdecznie dzi�kuj�\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2019s - loss: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21fc4198>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=32, nb_epoch=1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebra�y o tym, czy jakiekolwiek inicjatyw�, kt�rzy s� dotkni�ci chrzony polskich rodzin, cho�by fundamentalne znaczeniu � z ca�� pewno�ci� wspania�ym tego konkursu, wypitnie i to mocno podkre�la�� i nast�pcami �yczy� temu, �e ona zosta�y ustanowego by�a wtedy, �e jeszcze raz z panem prezydencki,\n",
      "doskona�y przyznawana jest tu, de tak�e jeszcze raz dzi�kuj� za to, �e on jest najlepsze jest silne i sprawiedliwo�ci, zapewniam swoj� spo�ecze�stwo w czo��wce.\n",
      " \n",
      "tak by�o w ci�gu ostatnich jak po to, �eby u\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1624s - loss: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6258a58>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebranicznych.\n",
      " \n",
      "po drugie, �eby by� wolny�.\n",
      " \n",
      "to trzeba wsp�praca\" si� rozwija� w jakim� sensie to one by�y pouczaj�ce i s�czeg�ln� do pierwszego pa�stwa. tak naprawd� w polsce. chcemy pami�ta�. mo�emy m�wi� �iawieli i kt�rego pocz�tku\", �e ta polska r�wnie� z pewnego naszego kraju i odwagi i tej przyja�ni ? o jednym: musz� pa�stwa. tak jak po prostu j� w produkcja wstali� ca�y czas nas � cho�by w polsce jest wielkie wzmocnienie naszego kraju, a tak�e wiele sprawami nad zwyk�ym wolno�� i wydoby� t\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1658s - loss: 0.8479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261e2ef0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebralonej �wiatowej, bo tak jak m�wi�em wspierali�my jej suwerenno��. my�l� tutaj jest najlepiej dla nich nie wyda� najbli�si.\n",
      " \n",
      "dlatego tak jak najbardziej prezydenta rzeczypospolitej bra� cz�onkostwo w polsce jest ogromnie to, co zawsze dla nich by�o odnowicielom sojuszu, buduj�c przede wszystkim bardzo cz�sto m�wimy ? kt�ry - najlepiej dla mnie wsp�lnie jest taka polska trybuna� w�gierskich miastach. to, prosz� pa�stwa, z naszego kraju jest tego, co nazywamy pewne obiektywne kryterii, kt�re ju� \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('data/char_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1656s - loss: 0.7968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1786f048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebralonalnych, si�ami w�adz regionalnych, sojuszniczych w tym konkursie, �eby by� w�a�nie z ozwarty na wnikomi, podobnym przez naszym wielkim zainteresowaniem izbysowych i wielkiego,\n",
      "szanowni pa�stwo.\n",
      " \n",
      "pa�stwa zak�ady poprzed tym, kt�rzy przyprowadzili�my do piel�gnowa�o si� do funkcjonuj�ca firm, fierzo tak�e jest tak,, �e mogli�my usi���, porozmawia� w walce o budowanie lepszej rzeczypospolitej szczyt nato w zakresie promowanie wielkie firmy b�d�ce efektem tego mojego wyst�pienia, dzi�kuj�.\n",
      "szcz\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2137s - loss: 0.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261a1208>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szanowny panie marszalku i szanowni zebrani go�cie!\n",
      " \n",
      "to dla mnie przede wszystkim tego, co zbudowa�o w ci�gu ? mo�liwo�ci �yciowe zosta�y wyr�wnane. pa�stwo pokoleniem jakby moich start-upowego, zdaj� sobie rad�, a kt�rej ludzko�� � mam nadziej� � b�dzie nale�a�a coraz wi�cej firm, sp�ek skarbu pa�stwa, dla mnie ogromnie pan b�g b�ogos�\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('data/char_rnnduda1-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
